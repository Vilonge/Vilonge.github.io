# üìù Publications

<div class='paper-box'>
    <div class='paper-box-image'>
        <div class="badge">ECCV 2024</div>
        <img src='images/pub/O2V-Mapping.png' alt="O2V-Mapping" width="100%">
    </div>
    <div class='paper-box-text' markdown="1">
        <a href="https://arxiv.org/abs/2404.06836">
            O2V-Mapping: Online Open-Vocabulary Mapping with Neural Implicit Representation
        </a>
        <br>
        Muer Tie, <strong>Julong Wei</strong>, Zhengjun Wang, Ke Wu, Shansuai Yuan, Kaizhao Zhang, Jie Jia, Jieru Zhao, Zhongxue Gan, Wenchao Ding
        <br>
        <a href="https://arxiv.org/abs/2404.06836"><strong>Project</strong>
        </a>
        /
        <a href="https://arxiv.org/abs/2404.06836"><strong>Paper</strong>
        </a>
        /
        <a href="https://arxiv.org/abs/2404.06836"><strong>Code</strong>
        </a>
        <ul>
            <li>We propose an <strong>O</strong>nline <strong>O</strong>pen <strong>V</strong>ocabulary mapping framework for online reconstruction and novel view rendering.</li>
            <li>We propose a feature fusion mechanism to address the issue of semantic spatiotemporal ambiguity in 3D scene understanding.
            </li>
            <li>We propose an LLM-centric agent utilizing O2V Field as interactive memory for embodied planning within global scene.
            </li>
        </ul>
    </div>
</div>
